Tuning the TCP/IP Stack 
Depending on your workload, number of connections, and client connect rates, you need to tune the Linux TCP/IP stack to provide you with adequate network performance and throughput.
The following script represents the recommended network (TCP/IP) tuning parameters for a Vertica cluster. Other network characteristics may affect how much these parameters optimize your throughput.
Add the following parameters to the /etc/sysctl.conf file. The changes take effect after the next reboot.
##### /etc/sysctl.conf
 # Increase number of incoming connections 
 net.core.somaxconn = 1024 
 #Sets the send socket buffer maximum size in bytes.
 net.core.wmem_max = 16777216
 #Sets the receive socket buffer maximum size in bytes.
 net.core.rmem_max = 16777216
 #Sets the receive socket buffer default size in bytes.
 net.core.wmem_default = 262144
 #Sets the receive socket buffer maximum size in bytes.
 net.core.rmem_default = 262144
 #Sets the maximum number of packets allowed to queue when a particular
 #interface receives packets faster than the kernel can process them.
 #increase the length of the processor input queue 
 net.core.netdev_max_backlog = 100000 
 net.ipv4.tcp_mem = 16777216 16777216 16777216 
 net.ipv4.tcp_wmem = 8192 262144 8388608 
 net.ipv4.tcp_rmem = 8192 262144 8388608
 net.ipv4.udp_mem = 16777216 16777216 16777216 
 net.ipv4.udp_rmem_min = 16384 
 net.ipv4.udp_wmem_min = 16384
